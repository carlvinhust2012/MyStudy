# 简介
ERNIE 开源仓库（https://github.com/PaddlePaddle/ERNIE）目前对应的是 文心大模型 4.5 系列（2025-06-30 开源），整体代码结构围绕“推理部署”展开，不含完整训练代码，但给出了：
1）全套权重（MoE & Dense）
2）基于 Paddle / PaddleInference 的推理入口
3）多精度（FP16/BF16/INT8）与多硬件（GPU/CPU/昆仑/昇腾）示例
4）一键 web_demo & 微调（LoRA/QLoRA）脚本

# 总体目录
ERNIE/
├── README.md                    快速开始 + 性能指标
├── LICENSE                      Apache 2.0
├── ernie/                       模型定义 + 推理核心
├── deploy/                      多硬件部署方案
├── examples/                    可运行 demo（Python/C++/Shell）
├── tools/                       权重转换 / INT8 量化 / 合并 LoRA
├── scripts/                     数据预处理 / 微调 / 评估脚本
├── docs/                        中文技术报告 & API 说明
└── requirements.txt             最小依赖（paddle>=3.0.0）

# 目录详细拆解
ernie/
├── modeling_ernie.py            ErnieConfig + ErnieForCausalLM（标准 PaddleModel）
├── ernie_moe_layer.py           MoE FFN + 路由实现（Top-K + load balance loss）
├── generation_utils.py           beam / top-k / top-p / repetition penalty
└── init.py

deploy/
├── python/                      基于 PaddleInference 的高性能推理
│   ├── infer.py                 命令行一键推理（支持 stream）
│   └── utils.py                 FP16/BF16/INT8 自动切换
├── cpp/                         C++ 示例（Linux/Windows）
│   ├── CMakeLists.txt
│   └── infer_demo.cc
├── serving/                     PaddleServing 在线服务模板
│   ├── ernie_web_service.py     启动 http 服务
│   └── client.py                并发压测脚本
└── llm_int8/                    量化校准工具（KL 散度 + 动态 PD）

examples/
├── text_generation.py           基础文本生成 demo
├── web_demo_gradio.py           Gradio 网页聊天（带流式输出）
├── langchain_demo.py            LangChain 接入示例
└── moe/                         MoE 模型专用脚本（路由可视化）

tools/
├── convert_checkpoint.py        把 HuggingFace 权重 → Paddle 格式
├── merge_lora.py                推理前合并 LoRA 权重
├── quantize.py                  INT8 离线量化入口
└── eval/                        下游任务评估（CLUE/CMMLU/C-Eval）

scripts/
├── finetune_lora.sh             单卡/多卡 LoRA 微调
├── qlora.sh                     4-bit 量化 LoRA（显存 < 24 GB）
├── preprocess.py                继续预训练语料清洗
└── benchmark.sh                 吞吐 & 首 token 延迟压测

# 快速体验
git clone https://github.com/PaddlePaddle/ERNIE
cd ERNIE
pip install -r requirements.txt
#下载 47B-MoE 权重（脚本自动拉取）
bash scripts/download_47b.sh
#交互式生成
python examples/web_demo_gradio.py --model_name_or_path ernie-47b-moe --dtype bfloat16
浏览器打开 http://0.0.0.0:7860 即可对话。

# 关键技术
张量并行已在 modeling_ernie.py 内置，paddle.distributed.fleet 启动即可多卡推理。
MoE 负载均衡 loss 写在 ernie_moe_layer.py 的 aux_loss 字段，训练/推理都会返回，方便继续预训练时监控。
INT8 量化采用 LLM.int8() 方案：对 nn.Linear 做 weight_quantize + input_dequant，校准集 512 条中文维基即可。
生成接口与 HuggingFace 对齐，支持 generate(..., do_sample=True, top_p=0.9, temperature=0.7)，切回 PyTorch 无成本。
